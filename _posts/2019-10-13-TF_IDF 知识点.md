# TF-IDF 知识点

## 名词解释

TF：词频，term frequency。即一个单词出现的次数；

IDF：逆文档频率，inverse document frequency.

## 原因

1. 单纯以词频来判断文档的类型是无效的，因为出现最多的词是 --- “是”、“的”、“在” --- 这一类最常用的词，即停用词：这些词对找到结果毫无帮助、必须过滤掉的词；
2. 假设把停用词过滤掉了，只考虑剩下的有实际意义的词。但是仍有问题，假设某个文档出现了“中国”、“蜜蜂”、“养殖”这三个词出现的次数一样多，但是其对于文档来说重要性不一样。因为“中国”这个词在所有文档中出现的次数比较多。

总结以上两点：**如果某个词比较少见，但是它在这篇文章中多次出现，那么它可能就反映了这篇文章的特性，正式我们所需要的关键词。**

## 计算词频

​	词频（TF） = 某个词在文章中的出现次数。但是考虑到文章有长短之分，为了便于不同文章的比较，进行“词频”标准化：

$$
词频(TF) = \frac{某个词在文章中的出现次数}{文章的总词数}
$$
或者

$$
词频(TF) = \frac{某个词中文章中的出现次数}{该文出现次数最多的词的出现次数}
$$


## 计算逆文档频率

​	这时，需要一个语料库（corpus），用来模拟语言的使用环境，计算公式：

$$
逆文档频率(IDF) = log(\frac{语料库的文档总数}{包含该词的文档数+1})
$$
如果一个词越常见，那么分母就越大，逆文档频率就越小越接近0。分母之所以加 1， 是为了避免分母为 0（即所有文档都不包含该次的情况）。log 表示对得到的值取对数。

## 计算 TF-IDF

TF-IDF = 词频（TF） x 逆文档频率（IDF）

上述式子可以得出：TF-IDF 与一个词在文档中的出现次数成正比，与该词在整个语言中的出现次数成反比。

**自动提取关键词的算法就很清楚了，就是计算出文档的每个词的 TF-IDF 值，然后按降序排列，取排在最前面的几个词即可。**

## 优缺点

### 优点：

1. 简单快速

### 缺点：

1. 单词以`词频` 衡量一个词的重要性，不够全面，有时重要的词可能出现次数并不多。
2. 无法体现词的位置信息，出现位置靠前的词语和出现位置靠后的词，都被视为重要性相同。

## 应用场景

1.  一般特征工程阶段中作为词在文本中的权重，用于体现该词对所在文本的重要性。
2. 一个文本向量化的表示方式：作为文本的向量表示。