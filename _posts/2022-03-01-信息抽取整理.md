# 信息抽取

信息抽取是构建大规模知识图谱的必备关键，先来说一下图谱的三元组形式，在以往常常将三元组以 (**head，relation, tail**) 的形式表示，在这里以(**subject, relation, object**)的形式表示，即**(S， R，O)。**

**信息抽取**分为两大部分，一部分是**命名实体识别**，识别出文本中的实体，另外就是**关系抽取**，对识别出来的实体构建对应的关系，两者便是构建三元组的基本组成。

# 1. 关系抽取 - 联合抽取

在以往的研究工作中，早期两个任务以pipline的方式进行，先做命名实体识别，然后做关系抽取。但是pipline的流程可能造成实体的识别错误，也就造成关系构建的错误，所以后续的一些研究工作将两者采用联合学习的方式。

传统pipeline的方式一个是容易造成错误传递，如实体识别错误；另外一个则是在关系分类中容易造成大量无效计算，即大部分实体之间是没有关系的。主要也无法解决 EPO 和 SEO 等问题。

1. Normal：代表没有重叠的部分；
2. EPO(EntityPairOverlap)：关系两端的实体都是一致，例如 QT 既在电影 DU 中扮演角色，又是电影 DU 的执导。
3. SEO(SingleEntityOverlap)：关系两端只有单个实体共享，图中的例子，从小范围来说，JRB 出生在 Washington，但是 Washington 是 USA 的首都，所以也可以说 JRB 出生在 USA。

![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled.png)

**以往工作的不足以及重叠三元组出现的挑战**：

1. 在实体对的组合之中，大多数实体对是没有关系链接的，这便存在很多的负例，也就造成了关系分类的不平衡。
2. 重叠三元组的问题更是一个难点，因为其存在共享的实体，甚至两个实体存在多种关系，这便增加了难度，没有足够的训练数据，是难以学习或者根本无法学习这种关系的。

以下列举几个解决上述问题的联合抽取的方案：

## 1.1. CASREL

为了解决上述问题，CASREL 提出了一个联合任务的框架用于抽取三元组 (subject, relation, object)。其中抽取步骤如下：

1. 先抽取subject；
2. 然后再根据subject，识别除所有可能的 relation 以及对应的 object。

**模型框架图如下**：

![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 1.png)

### 1.1.1. BERT Encoder

主要对句子的词进行编码，获取每个词的隐层表示，可以采用 BERT 的任意一层。论文以 BERT 为主，但也可以替换为 LSTM 等网络结构。

### 1.1.2. Subject Tagger - Cascade Decoder

这部分主要是根据 BERT Encoder 获取到的词的隐层表示解码，构建两个二分类分类器预测 subject 的 start 和 end 索引位置，对每一个词计算其作为 start 和 end 的一个概率，并根据某个阈值，大于则标记为 1，否则标记为 0。公式如下：

![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 2.png)

这部分的优化目标是：

![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 3.png)

对于多个 subject 的情况，采用就近原则进行 start 和 end 的坐标匹配。样例详见上面的框架示意图。

### 1.1.3. Relation-specific object Tagger - Cascade Decoder

这部分就融合 BERT Encoder 和 Subject 的信息，同时识别出 subject 的 relation 和相关的 object。

这个模块的输入如下：

![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 4.png)

其中第一项是 BERT Encoder 的输出；第二项是 subject 的特征向量。即 subject 对应的词的 embeding，如多个词则取平均。

另外，为了解决前面提到的 EPO 和 SEO 的问题，这里采用分别对每一种关系进行解码，分别输出两个序列，各代表该 subject 和 relation 所对应的 object 的 start 和 end 的索引位置。如一种关系下存在多个 object，此处仍采用就近原则进行匹配解码，公式如下：

![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 5.png)

这一模块的优化函数为：

![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 6.png)

CASREL 分析：

首先通过两个 Cascade Decoder 的设计，确实解决了 SEO 和 EPO 的重叠问题，以及半指针-半监督的标注方式也解决了命名实体中嵌套的问题。但是这个联合抽取的结构存在一个**暴露偏差**的问题，即在relation-specific object Tagger 模块中输入的 subject 在训练采用真实的标注的 subject 作为输入，但是推理时采用bert encoder 的输出，这会导致两者分布不一样的问题。

论文地址：[https://arxiv.org/abs/1909.03227](https://arxiv.org/abs/1909.03227)

## 1.2. TPLinker

TPLinker 是在一个模型实现真正意义上的单阶段联合抽取，而且在解决了EntityPairOverlap (EPO) 和 SingleEntityOverlap (SEO) 的问题的同时，且不存在曝光偏差的问题，保证了训练和测试的一致性。

该论文的贡献：提出了一种新的实体关系联合抽取标注方案，可以在一个模型中实现真正意义上的单阶段联合抽取，在同时解决EntityPairOverlap (EPO) 和 SingleEntityOverlap (SEO) 问题，且不存在曝光偏差，保证训练和测试的一致性。

备注：

曝光误差：以往提出的一些方法已经可以解决重叠问题，如 CopyRE 、CopyMTL、CasRel（HBT）等，但它们在训练和推理阶段的不一致性导致存在曝光偏差。即在训练阶段，使用了golden truth 作为已知信息对训练过程进行引导，而在推理阶段只能依赖于预测结果。这导致中间步骤的输入信息来源于两个不同的分布，对性能有一定的影响。虽然这些方法都是在一个模型中对实体和关系进行了联合抽取，但从某种意义上它们“退化”成了“pipeline”的方法，即在解码阶段需要分多步进行,这也是它们存在曝光偏差的本质原因。

### 1.2.1. 标注结构

为了解决上述的问题，TPLinker 将联合抽取任务转换为一个token-pair链接问题，并引入了一种新的握手标记方案，将实体对中每个关系类型下的边界标记对齐。

![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 7.png)

如上图所示，共有三种握手标记：

1. 紫色代表两实体的头尾握手，即表示一个实体的头尾索引位置；
   
    ![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 8.png)
    
    如上图所示，上面矩阵中两个 1 标识即表示 New York City 和 De Blasio 两个实体；
    
2. 红色代表某个关系下两个实体头的握手；
   
    ![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 9.png)
    
    如上图所示，上面矩阵中的 1 表示某个关系下的两个实体头的索引位置，即 New York City 和 De Blasio 的实体头索引位置；
    
3. 蓝色代表某个关系下两个实体尾的握手；
   
    ![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 10.png)
    
    如上图所示，上面矩阵中的 1 表示某个关系下的两个实体尾的索引位置，即 New York City 和 De Blasio 的实体尾索引位置；
    

**优化内存**：

因为在实体标识标注时，标注位置是不会出现在左下角的位置；而对于关系中的实体头尾标注时，当 subject 的位置在 object 的后面时，才有可能出现标注在左下角。

所以论文为了优化内存将所有出现在左下角的标注映射到右上角，但是采用 2 来跟原本在右上角 1 的标识进行区分。如下图所示：

![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 11.png)

### 1.2.2. 模型结构

模型结构比较简单，具体如下图所示：

![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 12.png)

1. 输入输出
   
    输入：就是一个句子序列；
    
    输出：也就是对应 link type 的标注
    
    1. EH to ET - entity head to entity tail
       
        在矩阵中通过紫色颜色进行标注，标注一个实体的头尾索引位置；
        
    2. SH to OH - subject head to object head
       
        在矩阵中通过红色进行标注，标注某个关系下，subject 实体的头位置和 object 实体的头位置；
        
    3. ST to OT - subject tail to object tail
       
        在矩阵中通过蓝色进行标注，标注某个关系下，subject 实体的尾位置和 object 实体的尾位置。
        
    
    因为所有标注都在矩阵的右上角，故最后将上述三个类型的输出拉平再拼接在一起，如上图中橙色区域所示。
    
2. encoder
   
    encoder 包含两部分，一部分用于学习整个句子的编码表示，另一个部分进行token pair 的表示学习。
    
    1. 首先通过一个 basic encoder 对输入的句子中的每个词映射为一个低维包含上下文信息的向量表示；
    2. 然后采用 h_i,j 作为一个 token pair 的向量表示，然后采用以下公式进行计算，得到 token pair 的向量表示：
       
        ![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 13.png)
        
    
3. Handshaking Kernel
   
    这里利用一个统一的架构对 EH to ET , SH to OT 和 ST to OT 进行预测和表示；给定一个 token pair 后，那么这个 token pair 的 link type 通过以下方式进行计算：
    
    ![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 14.png)
    
4. decoding
   
    解码算法的伪代码如下：
    
    ![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 15.png)
    
5. loss function
   损失函数公式如下：
   
    ![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 16.png)
   

论文地址：[https://arxiv.org/abs/2010.13415](https://arxiv.org/abs/2010.13415)

## 1.3. Global pointer

global pointer 可以理解为是一个 token pair 的识别模型。

### 1.3.1. 什么是 Global Pointer

Global Pointer 分为两部分，一部分是句子上下文向量编码学习过程，即将句子转换为包含上下文信息的向量序列；另一部分是根据实体类型，分别计算各个片段的打分。

1. encoder
   
    采用 bert 等预训练模型，采用 bert 的输出作为句子的向量序列。
    
2. 打分部分
   
    首先通过两个矩阵运算，将句子向量序列变化为两个向量序列，公式如下：
    
    ![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 17.png)
    
    上面代表第 a 中类型实体所用的向量序列，那么打分公式如下：
    
    ![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 18.png)
    
    在这样的设计下，GlobalPointer事实上就是Multi-Head Attention的一个简化版而已，有多少种实体就对应多少个head，相比Multi-Head Attention去掉了***V***
    相关的运算。
    
    global pointer 是基于内积的 token-pair 识别模块，其实就是把每一类实体的 头尾 位置对应的 token -pair 识别出来。
    
3. 引入相对位置
   
    存在一个问题，就是上面的打分函数并没有句子位置的信息，假设一句话中，要识别的实体很多的情况下，那么如果没有相对位置信息输入的话，则会导致结果出错。
    
    为了解决这个问题，作者引入了他自己提出的旋转式位置编码，那么融合相对位置后的公式如下：
    
    ![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 19.png)
    
1. 内存优化
   
    从打分部分可以看到，针对每一个实体类型，就有多少个 W_q 和 W_k 的参数以及一个打分矩阵。那么每新增一种实体类型，就要新增 2Dd 个参数。这样容易导致参数量巨大。
    
    作者为了解决这个问题，将实体识别的步骤拆分为两步：
    
    1. 识别：对于任意类型 a，其打分矩阵必然有很多相似之处，因为对于大多数 token-pair 而言，他们代表的都是非实体，也就是没有必要为每种实体类型都设计独立的打分矩阵，也就是对所有的实体类型，共用一个打分矩阵；
    2. 分类：采用 特征拼接 + Dense层 来完成，即新的打分函数如下：
       
        ![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 20.png)
        
        这最后一项则是 特征拼接 + Dense 层 的结果。
        

模型输出结果样式：

![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 21.png)

### 1.3.2. Global Pointer 如何解决实体和关系的联合抽取问题

三元组抽取任务 (S, P, O) ，实际上可以理解为五元组 (SH, ST, P, OH, OT) 的抽取任务，分别是 subject 的首尾位置，关系，object 的首尾位置。

从概率图的角度来看，我们可以这样构建模型：

1. 设计一个五元组的打分函数 S(SH, ST, P, OH, OT)；
2. 训练时让标注的五元组 S(SH, ST, P, OH, OT) > 0，其余五元组则 S(SH, ST, P, OH, OT) < 0；
3. 预测时枚举所有可能的五元组，输出 S(SH, ST, P, OH, OT) > 0 的部分。

然而，直接枚举所有的五元组数目太多了。以目前的算力来看，一般最多也就接受长度平方级的计算量，所以进行如下一个模型假设：

![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 22.png)

下面对上面公式各项公式进行解析：

1. 第一项和第二项分别是对 subject 和 object 的首尾进行打分，即可以识别所有的 subject 和 object。
2. 第三项为以 subject 和 object 首 的特征作为它们自身的表征来进行一次匹配，进行对应关系的识别；
3. 第四项为以 subject 和 object 尾 的特征作为它们自身的表征来进行一次匹配，进行对应关系的识别；因为可能存在嵌套实体，所以需要加上 实体尾 的特征进行关系识别；

总结一下，global pointer 是如何解决实体和关系的联合抽取的问题的：

1. 首先将三元组抽取任务转换为一个基于 token pair 的识别任务，其中分别识别上述公式中的四项内容。这四项内容均可以通过 global pointer 来解决；
2. 待对上面四项内容识别出来后，通过取各项的交集，即要求的五元组，就是我们要求的三元组。

**loss function**：

这里采用的 loss function 则是作者之前提出的多标签交叉熵，一般形式如下：

![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 23.png)

这里作者为来提高训练速度，实现了一个稀疏版的多标签交叉熵：

![](https://gitee.com/kinda830/pic_bed/raw/master/Untitled 24.png)

参考地址：

1. [https://kexue.fm/archives/8373](https://kexue.fm/archives/8373)
2. [https://kexue.fm/archives/8877](https://kexue.fm/archives/8877)
3. [https://kexue.fm/archives/8888](https://kexue.fm/archives/8888)
